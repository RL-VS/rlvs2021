# Evolutionary reinforcement learning

## Abstract

Reinforcement learning traditionally takes inspiration from operant conditioning, that is, trial-and-error learning during the lifetime of the agent. However, evolution is another trial-and-error process that is very successful in nature. This process inspired many algorithms that can also solve reinforcement learning problems while using a very different set of metaphors; in that case, learning happens at the phylogenetic timescale, from generation to generation. While evolutionary learning has its strengths, it also raises its own challenges. In this class, we will focus on the representation problem “How can an artificial genotype describe a neural network that could be as complex as a brain?”—and the stepping stones problem—“what intermediate steps lead to an artifact as sophisticated as a brain?”. We will also draw parallels with traditional reinforcement learning methods and attempt to understand the strengths and weaknesses of each family of methods.

## Speakers

[Jean-Baptiste Mouret](jean-baptiste-mouret.md)  
[Dennis Wilson](dennis-wilson.md)

## Class material

+ [Introduction](class-material/evolutionary/light-virtual_school_evo_intro.pdf)
+ [Evolutionary Strategies](class-material/evolutionary/Evolutionary Strategies.ipynb)
([Colab](https://colab.research.google.com/github/RL-VS/rlvs2021/blob/main/docs/class-material/evolutionary/Evolutionary%20Strategies.ipynb))
+ [Multi-Objective Optimization](class-material/evolutionary/multi-objective_optimization.pdf)
+ [Neuroevolution](class-material/evolutionary/light-virtual_school_neat_hyperneat.pdf)
+ [Beyond the fitness function](class-material/evolutionary/light-virtual_school_qd.pdf)
+ [MAP-Elites tutorial](https://github.com/jbmouret/map_elites_tutorial)

Readings:

+ [https://www.nature.com/articles/s42256-018-0006-z](https://www.nature.com/articles/s42256-018-0006-z)  
+ [https://www.cell.com/iscience/fulltext/S2589-0042(20)30928-7](https://www.cell.com/iscience/fulltext/S2589-0042(20)30928-7)

