# Reinforcement Learning fundamentals

## Abstract

The overall goal of this session is to provide the RLVS participants with an overview of RL and an understanding of (some) key challenges. It should also introduce participants to issues that will be tackled in more detail in the following classes. We will follow the course of a notebook together and we will alternate between a "lecture" mode and small illustrative exercises (with corrections) that the participants will have time to try themselves. We will introduce the modeling fundamentals of Makov Decision Processes. Then we will move our way up from toy examples and fundamental algorithms to key challenges in RL. In particular, we will focus on three key structuring issues for the RL practitioner: the exploration/exploitation tradeoff, value function approximation, and optimality search. Along with the session, we will link each topic to the corresponding classes in RLVS.


## Speaker

[E. Rachelson](emmanuel-rachelson.md)

## Class material

[Notebook](class-material/rl_fundamentals/rlvs_rl_fundamentals.zip) ([colab](https://colab.research.google.com/github/RL-VS/rlvs2021/blob/main/docs/class-material/rl_fundamentals/RL%20fundamentals.ipynb)) ([Original repo](https://github.com/erachelson/rlvs_rl_fundamentals))   

<iframe width="560" height="315" src="https://www.youtube.com/embed/kPWmrgUMgy8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>