# Stochastic bandits

## Abstract

The bandit framework specialises the reinforcement learning setup by removing the (controlled) state. Bandits provide all the essential ingredients to study the exploration/exploitation dilemma, with many principles derived for bandits generalising to the reinforcement learning setting. The simplification has the advantage that it permits a more complete understanding and practical algorithms. Furthermore, bandits are a good model for many applications.

I will introduce bandit problems and present the most well known algorithms based on the principle of optimism in the face of uncertainty. There will be a live coding demo and discussions of the many extensions needed in practical applications.

## Speaker

[Tor Lattimore](tor-lattimore.md)

## Class material

[Slides](class-material/stochastic-bandits-mcts/Lattimore-slides.pdf)
[The Bandit Algorithms book](https://tor-lattimore.com/downloads/book/book.pdf)

