# Symbolic representations and reinforcement learning

## Abstract

A remarkable property of deep learning algorithms is their ability to learn useful task-specific representations from data directly without the need for hand-crafted feature engineering. As they have grown in popularity over the past decade deep neural networks (NNs) have been successfully applied to a wide range of machine learning tasks, achieving state of the art results across many research areas. However, as the complexity of the research problems increase some of the limitations of NN become increasingly clear: NNs suffer from interpretability issues, poor generalisation that leads to very data-hungry algorithms and the inability to be combined with other old, well established AI algorithms. Some of the research tackling these drawbacks takes inspiration from symbolic AI. It focusses, for example, on obtaining interpretable representations from NNs or thinking about objects and relations when building network architectures. This talk reviews symbolic approaches and properties that might be interesting to keep in the back of our heads for current representation learning and reviews current research that merges deep and symbolic methods with an emphasis on methods applied to reinforcement learning.

## Speaker

[Marta Garnelo](marta-garnelo.md)

## Class material
[Video](https://us02web.zoom.us/rec/play/8WNwEhL1oLCoJeJzKlsmk-cK3Mszqy35m8qtXAQ6U8q4i5gowKUCQlUyzWbkYl3RupRf-MUQRG0_xQpD.f0O6D5zKg7bIbPPB?startTime=1617971766000&_x_zm_rtaid=ymYVeH5TS-yFo43GnN8WBA.1618294478147.5eaefc2413c244edb1d881fa39ddc8c2&_x_zm_rhtaid=167)


